#!/usr/bin/env python3
"""
æµ‹è¯•è„šæœ¬ï¼šæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ OpenAI SDK è°ƒç”¨æˆ‘ä»¬çš„æœ¬åœ° AI æœåŠ¡
This script demonstrates how to use OpenAI SDK to call our local AI service
"""

import asyncio
import httpx
import json
from typing import List, Dict

# å¦‚æœä½ æƒ³ä½¿ç”¨çœŸæ­£çš„ OpenAI SDKï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
# import openai

BASE_URL = "http://localhost:8000"
DEV_TOKEN = "dev-token"  # å¼€å‘æ¨¡å¼ä¸‹ä½¿ç”¨çš„æµ‹è¯• token


class OpenAICompatibleClient:
    """OpenAI å…¼å®¹çš„å®¢æˆ·ç«¯ç±»"""

    def __init__(self, base_url: str, api_key: str):
        self.base_url = base_url
        self.api_key = api_key
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }

    async def list_models(self) -> Dict:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{self.base_url}/v1/models", headers=self.headers
            )
            return response.json()

    async def create_chat_completion(
        self,
        model: str,
        messages: List[Dict],
        temperature: float = 0.7,
        max_tokens: int = None,
        stream: bool = False,
    ) -> Dict:
        """åˆ›å»ºèŠå¤©å®Œæˆ"""
        payload = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "stream": stream,
        }
        if max_tokens:
            payload["max_tokens"] = max_tokens

        async with httpx.AsyncClient(timeout=30.0) as client:
            if stream:
                return await self._handle_streaming_response(client, payload)
            else:
                response = await client.post(
                    f"{self.base_url}/v1/chat/completions",
                    headers=self.headers,
                    json=payload,
                )
                return response.json()

    async def _handle_streaming_response(
        self, client: httpx.AsyncClient, payload: Dict
    ):
        """å¤„ç†æµå¼å“åº”"""
        print("ğŸ”„ å¼€å§‹æµå¼å“åº”...")

        full_content = ""
        async with client.stream(
            "POST",
            f"{self.base_url}/v1/chat/completions",
            headers=self.headers,
            json=payload,
        ) as response:
            async for chunk in response.aiter_text():
                if chunk.strip():
                    lines = chunk.strip().split('\n')
                    for line in lines:
                        if line.startswith('data: '):
                            data = line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                            if data == '[DONE]':
                                print("\nâœ… æµå¼å“åº”å®Œæˆ")
                                break
                            try:
                                chunk_data = json.loads(data)
                                if 'choices' in chunk_data and chunk_data['choices']:
                                    delta = chunk_data['choices'][0].get('delta', {})
                                    content = delta.get('content', '')
                                    if content:
                                        print(content, end='', flush=True)
                                        full_content += content
                            except json.JSONDecodeError:
                                continue

        return {"content": full_content}


async def test_openai_compatible_api():
    """æµ‹è¯• OpenAI å…¼å®¹çš„ API"""

    print("ğŸš€ æµ‹è¯• OpenAI å…¼å®¹ API")
    print("=" * 50)

    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = OpenAICompatibleClient(BASE_URL, DEV_TOKEN)

    try:
        # 1. æµ‹è¯•æ¨¡å‹åˆ—è¡¨
        print("\nğŸ“‹ æµ‹è¯•è·å–æ¨¡å‹åˆ—è¡¨...")
        models = await client.list_models()
        print(f"âœ… å¯ç”¨æ¨¡å‹: {len(models['data'])} ä¸ª")
        for model in models['data']:
            print(f"   - {model['id']} (owned by: {model['owned_by']})")

        # 2. æµ‹è¯•æ™®é€šèŠå¤©å®Œæˆ
        print("\nğŸ’¬ æµ‹è¯•æ™®é€šèŠå¤©å®Œæˆ...")
        messages = [
            {"role": "user", "content": "è¯·è§£é‡Šä»€ä¹ˆæ˜¯äºŒæ¬¡æ–¹ç¨‹ï¼Œå¹¶ç»™å‡ºä¸€ä¸ªç®€å•çš„ä¾‹å­"}
        ]

        response = await client.create_chat_completion(
            model="gpt-4-tutor", messages=messages, temperature=0.7, max_tokens=300
        )

        print("âœ… å“åº”å†…å®¹:")
        print(response['choices'][0]['message']['content'])
        print(f"\nğŸ“Š Token ä½¿ç”¨æƒ…å†µ: {response['usage']}")

        # 3. æµ‹è¯•æµå¼å“åº”
        print("\nğŸŒŠ æµ‹è¯•æµå¼èŠå¤©å®Œæˆ...")
        stream_messages = [{"role": "user", "content": "ç”¨ç®€å•çš„è¯è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ "}]

        await client.create_chat_completion(
            model="local-tutor", messages=stream_messages, temperature=0.8, stream=True
        )

        # 4. æµ‹è¯•å¤šè½®å¯¹è¯
        print("\n\nğŸ”„ æµ‹è¯•å¤šè½®å¯¹è¯...")
        conversation = [{"role": "user", "content": "ä½ å¥½ï¼Œæˆ‘æƒ³å­¦ä¹  Python ç¼–ç¨‹"}]

        response = await client.create_chat_completion(
            model="gpt-3.5-turbo-tutor", messages=conversation, temperature=0.6
        )

        assistant_reply = response['choices'][0]['message']['content']
        print(f"ğŸ¤– AI å¯¼å¸ˆ: {assistant_reply}")

        # ç»§ç»­å¯¹è¯
        conversation.append({"role": "assistant", "content": assistant_reply})
        conversation.append({"role": "user", "content": "é‚£æˆ‘åº”è¯¥ä»å“ªé‡Œå¼€å§‹å­¦ä¹ å‘¢ï¼Ÿ"})

        response = await client.create_chat_completion(
            model="gpt-3.5-turbo-tutor", messages=conversation, temperature=0.6
        )

        print(f"\nğŸ¤– AI å¯¼å¸ˆ: {response['choices'][0]['message']['content']}")

        # 5. æµ‹è¯•ä¸åŒå­¦ç§‘
        print("\n\nğŸ“š æµ‹è¯•ä¸åŒå­¦ç§‘çš„å“åº”...")
        subjects = [
            "è§£é‡Šå…‰åˆä½œç”¨çš„è¿‡ç¨‹",
            "ä»€ä¹ˆæ˜¯å¾®ç§¯åˆ†ä¸­çš„å¯¼æ•°ï¼Ÿ",
            "å¦‚ä½•å­¦å¥½è‹±è¯­è¯­æ³•ï¼Ÿ",
        ]

        for i, subject in enumerate(subjects, 1):
            print(f"\n{i}. é—®é¢˜: {subject}")
            response = await client.create_chat_completion(
                model="local-tutor",
                messages=[{"role": "user", "content": subject}],
                temperature=0.5,
            )
            print(f"   å›ç­”: {response['choices'][0]['message']['content'][:100]}...")

    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")


async def test_with_real_openai_sdk():
    """ä½¿ç”¨çœŸæ­£çš„ OpenAI SDK æµ‹è¯•ï¼ˆéœ€è¦å®‰è£… openai åŒ…ï¼‰"""

    try:
        import openai

        print("\nğŸ”§ ä½¿ç”¨çœŸæ­£çš„ OpenAI SDK æµ‹è¯•...")
        print("=" * 50)

        # é…ç½® OpenAI å®¢æˆ·ç«¯æŒ‡å‘æˆ‘ä»¬çš„æœåŠ¡
        openai.api_base = f"{BASE_URL}/v1"
        openai.api_key = DEV_TOKEN

        # æµ‹è¯•èŠå¤©å®Œæˆ
        response = await openai.ChatCompletion.acreate(
            model="gpt-4-tutor",
            messages=[
                {"role": "user", "content": "ç”¨ OpenAI SDK æµ‹è¯•: è§£é‡Šä»€ä¹ˆæ˜¯ç®—æ³•"}
            ],
            temperature=0.7,
        )

        print("âœ… OpenAI SDK æµ‹è¯•æˆåŠŸ!")
        print(f"å“åº”: {response.choices[0].message.content}")

    except ImportError:
        print("âš ï¸  æœªå®‰è£… openai åŒ…ï¼Œè·³è¿‡ OpenAI SDK æµ‹è¯•")
        print("   å¯ä»¥é€šè¿‡ 'uv add openai' å®‰è£…")
    except Exception as e:
        print(f"âŒ OpenAI SDK æµ‹è¯•å¤±è´¥: {e}")


def create_usage_examples():
    """åˆ›å»ºä½¿ç”¨ç¤ºä¾‹ä»£ç """

    examples = {
        "python_client.py": '''
# Python å®¢æˆ·ç«¯ç¤ºä¾‹
import httpx
import asyncio

async def chat_with_ai_tutor():
    headers = {"Authorization": "Bearer dev-token", "Content-Type": "application/json"}
    
    payload = {
        "model": "gpt-4-tutor",
        "messages": [
            {"role": "user", "content": "è§£é‡Šä»€ä¹ˆæ˜¯é€’å½’ç®—æ³•"}
        ],
        "temperature": 0.7
    }
    
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/v1/chat/completions",
            headers=headers,
            json=payload
        )
        
        result = response.json()
        print(result["choices"][0]["message"]["content"])

asyncio.run(chat_with_ai_tutor())
        ''',
        "openai_sdk_example.py": '''
# ä½¿ç”¨ OpenAI SDK çš„ç¤ºä¾‹
import openai

# é…ç½® OpenAI SDK æŒ‡å‘æˆ‘ä»¬çš„æœåŠ¡
openai.api_base = "http://localhost:8000/v1"
openai.api_key = "dev-token"

# ç°åœ¨ä½ å¯ä»¥åƒä½¿ç”¨ OpenAI API ä¸€æ ·ä½¿ç”¨æˆ‘ä»¬çš„æœåŠ¡
response = openai.ChatCompletion.create(
    model="gpt-4-tutor",
    messages=[
        {"role": "user", "content": "æ•™æˆ‘å­¦ä¹ æ•°æ®ç»“æ„"}
    ]
)

print(response.choices[0].message.content)
        ''',
        "curl_example.sh": '''
#!/bin/bash
# cURL ç¤ºä¾‹

# è·å–æ¨¡å‹åˆ—è¡¨
curl -X GET "http://localhost:8000/v1/models" \\
  -H "Authorization: Bearer dev-token"

# èŠå¤©å®Œæˆ
curl -X POST "http://localhost:8000/v1/chat/completions" \\
  -H "Authorization: Bearer dev-token" \\
  -H "Content-Type: application/json" \\
  -d '{
    "model": "gpt-4-tutor",
    "messages": [
      {"role": "user", "content": "è§£é‡Šæœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ"}
    ],
    "temperature": 0.7
  }'
        ''',
    }

    print("\nğŸ“ åˆ›å»ºä½¿ç”¨ç¤ºä¾‹æ–‡ä»¶...")
    for filename, content in examples.items():
        with open(f"examples_{filename}", "w", encoding="utf-8") as f:
            f.write(content.strip())
        print(f"   âœ… åˆ›å»ºäº† examples_{filename}")


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– AI Tutor Service - OpenAI å…¼å®¹ API æµ‹è¯•")
    print("=" * 60)

    # æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{BASE_URL}/health")
            if response.status_code == 200:
                print("âœ… æœåŠ¡è¿è¡Œæ­£å¸¸")
            else:
                print("âŒ æœåŠ¡å¼‚å¸¸")
                return
    except Exception as e:
        print(f"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡: {e}")
        print("è¯·ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œ: uv run python scripts/dev.py run")
        return

    # è¿è¡Œæµ‹è¯•
    await test_openai_compatible_api()
    await test_with_real_openai_sdk()

    # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
    create_usage_examples()

    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ! ä½ çš„ OpenAI å…¼å®¹ API æœåŠ¡å·¥ä½œæ­£å¸¸")
    print("\nğŸ“š ä¸»è¦ç‰¹æ€§:")
    print("   âœ… å®Œå…¨å…¼å®¹ OpenAI API æ ¼å¼")
    print("   âœ… æ”¯æŒæ™®é€šå’Œæµå¼å“åº”")
    print("   âœ… æ™ºèƒ½æ•™å­¦å“åº”")
    print("   âœ… å¤šæ¨¡å‹æ”¯æŒ")
    print("   âœ… å¯ä»¥ä½¿ç”¨ç°æœ‰çš„ OpenAI SDK")


if __name__ == "__main__":
    asyncio.run(main())
